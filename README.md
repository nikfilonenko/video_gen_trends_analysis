# About the project ***`video_gen_trends_analysis`***

## üìä –ù–æ—É—Ç–±—É–∫ —Å –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–º –∑–∞–¥–∞–Ω–∏–µ–º: [–ó–¥–µ—Å—å](src/notebooks/arXiv_video_generation_trends.ipynb)

`src/notebooks/arXiv_video_generation_trends.ipynb`

<br>

## üìÉ –ù–æ—É—Ç–±—É–∫ –Ω–∞ google colab: [–ó–¥–µ—Å—å](https://colab.research.google.com/drive/1CgY7crZzAQyeoNTpKLkrM6AvO8LLqc-C?usp=sharing)

`google colab`

### –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞](#01)
2. [–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ arXiv API](#02)
3. [EDA + –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞](#03)
4. [–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º/—Ç—Ä–µ–Ω–¥–æ–≤](#04)
   - [–¢–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ LDA](#041)
   - [–¢–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ NMF](#042)
   - [–ê–Ω–∞–ª–∏–∑ —Å BERTopic](#043)
5. [–ö–ª—é—á–µ–≤—ã–µ –≤—ã—è–≤–ª–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã](#05)
6. [–í—ã–≤–æ–¥](#06)

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ <a name="01"></a>

**–¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞**¬†- –≤—ã—è–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã –≤ –æ–±–ª–∞—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –≤ 2024 –≥–æ–¥—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –∏–∑ arXiv.

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ:**

- –°–±–æ—Ä 2100 —Å—Ç–∞—Ç–µ–π –∑–∞ 2024 –≥–æ–¥ —á–µ—Ä–µ–∑ arXiv API
    
- –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–µ—Ö –º–µ—Ç–æ–¥–æ–≤ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è:
    
    - LDA (Latent Dirichlet Allocation)
        
    - NMF (Non-Negative Matrix Factorization)
        
    - BERTopic (–Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)
        
- –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ç—Ä–µ–Ω–¥–æ–≤


### –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ arXiv API <a name="02"></a>

–î–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π API arXiv, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–¥–æ–±–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π

–¢–∞–∫–∂–µ –±—ã–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ arXiv, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–¥–æ–±–Ω—É—é –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—É—é –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—é –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å API arXiv

- —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:

```python
query = (
    'all:video generation OR all:video synthesis OR '
    'all:diffusion video OR all:GAN video OR '
    'all:text-to-video OR all:image-to-video OR '
    'all:scene generation '
    'AND submittedDate:[20240101 TO 20241231]'
)
```

–í –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫ —ç—Ç–æ–º—É:

- –±—ã–ª–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏)
- –±—ã–ª–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≥–æ–¥—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏

#### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–±–æ—Ä–∞:

- –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ —Å—Ç–∞—Ç–µ–π:¬†**2100**
    
- –ü–µ—Ä–∏–æ–¥: —Ç–æ–ª—å–∫–æ¬†**2024 –≥–æ–¥**

    
–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:
    
 - –ó–∞–≥–æ–ª–æ–≤–æ–∫ (`title`)
     
 - –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è (`abstract`)
     
 - –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (`published`)
     
 - –°–ø–∏—Å–æ–∫ –∞–≤—Ç–æ—Ä–æ–≤ (`authors`)
     
 - –°—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç–∞—Ç—å—é (`url`)


### EDA + –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ <a name="03"></a>

–í —ç—Ç–æ–π —á–∞—Å—Ç–µ –∑–∞–¥–∞–Ω–∏—è —è –ø—Ä–æ–≤–µ–ª EDA –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è 

#### –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –æ –¥–∞–Ω–Ω—ã—Ö

–ë–∞–∑–æ–≤—ã–π EDA –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, –∞ –≤—Å–µ —Å—Ç–æ–ª–±—Ü—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ `object` (—Å—Ç—Ä–æ–∫–∞). –≠—Ç–æ –ª–æ–≥–∏—á–Ω–æ, —É—á–∏—Ç—ã–≤–∞—è —Ç–µ–∫—Å—Ç–æ–≤—É—é –ø—Ä–∏—Ä–æ–¥—É –¥–∞–Ω–Ω—ã—Ö. –û–¥–Ω–∞–∫–æ —Å—Ç–æ–ª–±–µ—Ü `published` –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Ç–∏–ø—É `datetime`, —á—Ç–æ–±—ã –≤—ã–¥–µ–ª–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ‚Äî –≥–æ–¥ –∏ –º–µ—Å—è—Ü –ø—É–±–ª–∏–∫–∞—Ü–∏–∏. –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç –≥–ª—É–±–∂–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏.

–ö–ª—é—á–µ–≤—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è:

- –°—Ç–æ–ª–±—Ü—ã `title`, `abstract` –∏ `url` —Å–æ–¥–µ—Ä–∂–∞—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (2100 –∏–∑ 2100).
    
- –í `published` 2098 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, —á—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π.
    
- `authors` —Å–æ–¥–µ—Ä–∂–∏—Ç 2091 —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Äî —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∞–≤—Ç–æ—Ä—Å–∫–∏–µ –∫–æ–ª–ª–µ–∫—Ç–∏–≤—ã –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π –≤ —Ç–µ—á–µ–Ω–∏–µ –≥–æ–¥–∞.
    

–í —Ü–µ–ª–æ–º, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–∞—è, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –æ—á–∏—Å—Ç–∫–∏. –í—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, `\n`), –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ `published` –∫ `datetime` –ø–æ–∑–≤–æ–ª–∏–ª–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å `year` –∏ `month`. –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—É–±–ª–∏–∫–∞—Ü–∏–π –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–≤—Ç–æ—Ä–æ–≤ –±—ã–ª–∞ –≤—ã—Å–æ–∫–æ–π –≤ –∫–æ–Ω—Ü–µ 2024 –≥–æ–¥–∞, –∞ —Ç–∞–∫–∂–µ –≤ –º–∞—Ä—Ç–µ.

---

#### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º –∏ —Ç—Ä–µ–Ω–¥–æ–≤ –≤ –≤–∏–¥–µ–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

–î–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —è —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª –µ–¥–∏–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π `title` –∏ `abstract`, —Ç–∞–∫ –∫–∞–∫ –∏–º–µ–Ω–Ω–æ –æ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏ —Å—Ç–∞—Ç–µ–π.

–î–∞–ª–µ–µ –≤—ã–ø–æ–ª–Ω–∏–ª –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–∞:

- –ü—Ä–∏–≤–µ–ª —Ç–µ–∫—Å—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É;
    
- –£–¥–∞–ª–∏–ª —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π;
    
- –ò—Å–∫–ª—é—á–∏–ª —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞;
    
- –í—ã–ø–æ–ª–Ω–∏–ª —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é;
    
- –ü—Ä–∏–º–µ–Ω–∏–ª –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é (—Ç–æ–ª—å–∫–æ –¥–ª—è count-based –º–µ—Ç–æ–¥–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ LDA –∏ NMF, —á—Ç–æ–±—ã —É–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞, –Ω–æ –Ω–µ –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö, –Ω–∞–ø—Ä–∏–º–µ—Ä BERTopic, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å —Ü–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö).
    

–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é **–Ω–µ –ø—Ä–∏–º–µ–Ω—è–ª** –¥–ª—è –º–µ—Ç–æ–¥–æ–≤, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, BERTopic), —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ –º–æ–≥–ª–∞ –±—ã –∏—Å–∫–∞–∑–∏—Ç—å —Å–º—ã—Å–ª –Ω–∞—É—á–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ —Å–Ω–∏–∑–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è.

- –ü—Ä–∏–º–µ—Ä –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å–ª–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏:

```
video video generative adversarial network fewshot learning based policy gradient development sophisticated model videotovideo synthesis facilitated recent advance deep reinforcement learning generative adversarial network gans paper propose new deep neural network approach based reinforcement learning unsupervised conditional videotovideo synthesis preserving unique style source video domain approach aim learn mapping source video domain target video domain train model using policy gradient employ convlstm layer capture spatial temporal information designing finegrained gan architecture incorporating spatiotemporal adversarial goal adversarial loss aid content translation preserving style unlike traditional videotovideo synthesis method requiring paired input proposed approach general require paired input thus dealing limited video target domain ie fewshot learning particularly effective experiment show produce temporally coherent video result result highlight potential approach advance videotovideo synthesis
```


- –ü—Ä–∏–º–µ—Ä –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ë–ï–ó –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏:

```
video video generative adversarial network fewshot learning based policy gradient development sophisticated models videotovideo synthesis facilitated recent advances deep reinforcement learning generative adversarial networks gans paper propose new deep neural network approach based reinforcement learning unsupervised conditional videotovideo synthesis preserving unique style source video domain approach aims learn mapping source video domain target video domain train model using policy gradient employ convlstm layers capture spatial temporal information designing finegrained gan architecture incorporating spatiotemporal adversarial goals adversarial losses aid content translation preserving style unlike traditional videotovideo synthesis methods requiring paired inputs proposed approach general require paired inputs thus dealing limited videos target domain ie fewshot learning particularly effective experiments show produce temporally coherent video results results highlight potential approach advances videotovideo synthesis
```

–î–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —è  —Ç–∞–∫–∂–µ –Ω–∞–ø–∏—Å–∞–ª –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä `CustomTextPreprocessor`, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–ø–æ–ª–Ω—è–µ—Ç –æ—á–∏—Å—Ç–∫—É, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é, —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ –∏, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é.

```python
import nltk

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import re

class CustomTextPreprocessor:
    def __init__(self, lemmatization=False):
        self.lemmatization = lemmatization
        self.stop_words = set(stopwords.words('english'))
        self.lemmatizer = WordNetLemmatizer()
        self.regex_pattern = r'[^\w\s]'

    def preprocess(self, text: pd.Series) -> pd.DataFrame:
        cleaned_txt = text.apply(lambda x: self._clean_text(x))

        if self.lemmatization:
            cleaned_txt = cleaned_txt.apply(lambda x: self._lemmatize_txt(x))

        result_df = pd.DataFrame({
            'text': cleaned_txt
        })
        return result_df

    def _clean_text(self, text: str) -> str:
        if not isinstance(text, str):
            return ""

        text = re.sub(self.regex_pattern, '', text)

        tokens = word_tokenize(
            text.lower()
        )

        tokens = [word for word in tokens if word not in self.stop_words and word.isalpha()]
        return " ".join(tokens)

    def _lemmatize_txt(self, text: str) -> str:
        if not isinstance(text, str) or not text:
            return ""

        tokens = word_tokenize(text)
        lemmas = [self.lemmatizer.lemmatize(token) for token in tokens]
        return " ".join(lemmas)
```


–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –ø–æ—Å–ª–µ —ç—Ç–∞–ø–∞ EDA –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –æ—á–∏—â–µ–Ω—ã, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ –¥–∞–ª—å–Ω–µ–π—à–µ–º—É –∞–Ω–∞–ª–∏–∑—É.





### –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º/—Ç—Ä–µ–Ω–¥–æ–≤ <a name="04"></a>

#### –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ LDA <a name="041"></a>



#### –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ NMF <a name="042"></a>

#### –ê–Ω–∞–ª–∏–∑ —Å BERTopic <a name="043"></a>


### –ö–ª—é—á–µ–≤—ã–µ –≤—ã—è–≤–ª–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã <a name="05"></a>
